{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mazowieckie_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPoiwj+obt+n8rKDvsCLFyY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KacperGrodecki/nieruchomosci-mazowieckie/blob/0.0.2/mazowieckie_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoyxUX4T7Yoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c145294-5423-4cb8-8e4c-ae17686d6f7f"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import svm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(7)\n",
        "from google.colab import drive\n",
        "import seaborn as sns\n",
        "drive.mount('/content/drive')\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "#from otoDomScraper import daneDomu\n",
        "#from random import randrange\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statistics\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn import preprocessing\n",
        "from IPython.display import Javascript\n",
        "import requests\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaSkJkDn7htz"
      },
      "source": [
        "def toNum2(txt):\n",
        "    if type(txt) is int:\n",
        "        return txt\n",
        "    elif (type(txt) is str):\n",
        "        digs = re.findall(r'\\d+', txt)\n",
        "        if len(digs) == 1:\n",
        "            return int(digs[0])\n",
        "        elif len(digs) == 2:\n",
        "            return 1000 * int(digs[0]) + int(digs[1])\n",
        "        elif len(digs) == 3:\n",
        "            return 1000000 * int(digs[0]) + 1000 * int(digs[1]) + int(digs[0])\n",
        "\n",
        "    #   return int(digs)\n",
        "\n",
        "\n",
        "def toNum1(txt):\n",
        "    if type(txt) is str:\n",
        "        digs = re.findall(r'\\d+', txt)\n",
        "        if len(digs) == 1:\n",
        "            return int(digs[0])\n",
        "        elif len(digs) == 2 and (txt[1] != ' '):\n",
        "            return int(digs[0]) + 0.01 * int(digs[1])\n",
        "        elif len(digs) == 3:\n",
        "            return 1000 * int(digs[0]) + int(digs[1]) + 0.001 * int(digs[2])\n",
        "        elif (type(txt) is str) and (txt[1] == ' '):\n",
        "            digs = re.findall(r'\\d+', txt)\n",
        "            return 1000 * int(digs[0]) + int(digs[1])\n",
        "    else:\n",
        "        return txt\n",
        "\n",
        "\n",
        "def toNum3(txt):\n",
        "    if type(txt) == int:\n",
        "        return txt\n",
        "    return int(re.findall(r'\\d+', txt)[0])\n",
        "\n",
        "def pietra(txt):\n",
        "    if type(txt) is str:\n",
        "        if '0' in txt:\n",
        "            return 0\n",
        "        if '1' in txt:\n",
        "            return 1\n",
        "        elif '2' in txt:\n",
        "            return 2\n",
        "        elif '3' in txt:\n",
        "            return 3\n",
        "        elif 'parterowy' in txt:\n",
        "            return 0\n",
        "    else:\n",
        "        return txt\n",
        "\n",
        "def cities(x):\n",
        "    dist=x.split()[4]\n",
        "    #city=x.split()[5]\n",
        "    if dist=='warszawski':\n",
        "        return x.split()[6]\n",
        "    elif dist in ['Warszawa','Radom','PÅ‚ock','Siedlce']:\n",
        "        return dist\n",
        "    else:\n",
        "        try:\n",
        "            return x.split()[5]\n",
        "        except:\n",
        "            return 'unknown'\n",
        "\n",
        "def region(x):\n",
        "    if x.split()[4]=='Warszawa':\n",
        "        try:\n",
        "            return x.split()[5]\n",
        "        except:\n",
        "            return ''\n",
        "    else:\n",
        "        return ''"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz6yc0BqdG-c"
      },
      "source": [
        "def get_voivodeships():\n",
        "    # problem - too many voivodeships, historical ones are mixed together\n",
        "    # solution - just cut the list after 16-th item\n",
        "    \n",
        "    # request voivodeships of poland(wd:Q36),\n",
        "    # cut after 16 voivodeships, the rest are historical ones\n",
        "    # https://query.wikidata.org/#%20%20%20%20SELECT%20%3Fvoivodeship%20%3FvoivodeshipLabel%20%3Flatitude%20%3Flongitude%20%3Fadmininistrative_teritorial_entity%0A%20%20%20%20WHERE%20%7B%0A%20%20%20%20%20%20%3Fvoivodeship%20wdt%3AP31%20wd%3AQ150093%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wdt%3AP131%20%3Fadmininistrative_teritorial_entity%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20p%3AP625%2Fpsv%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLatitude%20%3Flatitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLongitude%20%3Flongitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D.%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20FILTER%28%3Fadmininistrative_teritorial_entity%20%3D%20wd%3AQ36%29.%0A%20%20%20%20%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22pl%22.%20%7D%0A%20%20%20%20%7D%0A%20%20%20%20ORDER%20BY%20DESC%28%3Fvoivodeship%29%0A%20%20%20%20LIMIT%2016%0A\n",
        "    url = 'https://query.wikidata.org/sparql'\n",
        "    query = '''\n",
        "    SELECT ?voivodeship ?voivodeshipLabel ?latitude ?longitude ?admininistrative_teritorial_entity\n",
        "    WHERE {\n",
        "      ?voivodeship wdt:P31 wd:Q150093;\n",
        "                   wdt:P131 ?admininistrative_teritorial_entity;\n",
        "                   p:P625/psv:P625 [\n",
        "                       wikibase:geoLatitude ?latitude ;\n",
        "                       wikibase:geoLongitude ?longitude ;\n",
        "                   ].               \n",
        "      FILTER(?admininistrative_teritorial_entity = wd:Q36).\n",
        "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"pl\". }\n",
        "    }\n",
        "    ORDER BY DESC(?voivodeship)\n",
        "    LIMIT 16\n",
        "    '''\n",
        "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
        "    data = r.json()\n",
        "\n",
        "    # convert json to dataframe\n",
        "    voivodeships = []\n",
        "    for item in data['results']['bindings']:\n",
        "        voivodeships.append(OrderedDict(\n",
        "        {\n",
        "            'voivodeship':      item['voivodeshipLabel']['value'].lower(),\n",
        "            'latitude':         float(item['latitude']['value']),        \n",
        "            'longitude':        float(item['longitude']['value']),                    \n",
        "            'wikidata_item_id': item['voivodeship']['value'].split('/')[-1]\n",
        "        }))\n",
        "    #     print(item,'\\n')    \n",
        "    return pd.DataFrame(voivodeships)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnwWwv4vdeob"
      },
      "source": [
        "def get_warsaw_districts():\n",
        "    # problem  - some districts have two sets of coordinates which differ slighlty\n",
        "    # solution - drop the one with worse precision (larger value), this seems to be consistent with the wikipedia data\n",
        "    # to do    - the above is not true for ['Wola'], change it\n",
        "    \n",
        "    # https://query.wikidata.org/#SELECT%20%3Fdistrict_of_Warsaw%20%3Fdistrict_of_WarsawLabel%20%3Flat%20%3Flon%20%3FgeoPrecision%20%0AWHERE%20%7B%0A%20%20%3Fdistrict_of_Warsaw%20%20wdt%3AP31%20wd%3AQ4286337%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wdt%3AP17%20wd%3AQ36%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wdt%3AP131%20wd%3AQ270%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20p%3AP625%2Fpsv%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLatitude%20%3Flat%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLongitude%20%3Flon%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoPrecision%20%20%3FgeoPrecision%3B%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22pl%22.%20%7D%0A%7D\n",
        "    url = 'https://query.wikidata.org/sparql'\n",
        "    query = '''\n",
        "    SELECT ?warsaw_district ?warsaw_districtLabel ?latitude ?longitude ?geoPrecision \n",
        "    WHERE {\n",
        "      ?warsaw_district  wdt:P31 wd:Q4286337;\n",
        "                           wdt:P17 wd:Q36;\n",
        "                           wdt:P131 wd:Q270;\n",
        "                           p:P625/psv:P625 [\n",
        "                               wikibase:geoLatitude ?latitude ;\n",
        "                               wikibase:geoLongitude ?longitude ;\n",
        "                               wikibase:geoPrecision  ?geoPrecision;                                       \n",
        "                           ]\n",
        "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"pl\". }\n",
        "    }\n",
        "    ORDER BY ASC(?warsaw_districtLabel)\n",
        "    '''\n",
        "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
        "#     print(r.json())\n",
        "    data = r.json()\n",
        "\n",
        "    # convert json to dataframe\n",
        "    warsaw_districts = []\n",
        "    for item in data['results']['bindings']:\n",
        "#         print(item,'\\n')    \n",
        "        warsaw_districts.append(OrderedDict(\n",
        "        {\n",
        "            'warsaw_district':  item['warsaw_districtLabel']['value'].lower(),\n",
        "            'latitude':         float(item['latitude']['value']),        \n",
        "            'longitude':        float(item['longitude']['value']),                    \n",
        "            'geoPrecision':     float(item['geoPrecision']['value']),                                \n",
        "            'wikidata_item_id': item['warsaw_district']['value'].split('/')[-1]\n",
        "        }))\n",
        "    \n",
        "    warsaw_districts = pd.DataFrame(warsaw_districts).sort_values(by=['warsaw_district'])\n",
        "    \n",
        "    # if duplicate warsaw districts exist, take the one with better precision (lower value), do the opposite in case of 'Wola' \n",
        "    for district in warsaw_districts['warsaw_district']:\n",
        "        if np.sum(warsaw_districts['warsaw_district'] == district) > 1: # duplicate district found\n",
        "            if district != 'wola':            \n",
        "                district_to_drop_idx = warsaw_districts.loc[warsaw_districts['warsaw_district'] == district, 'geoPrecision'].idxmax()\n",
        "            elif district == 'wola':\n",
        "                district_to_drop_idx = warsaw_districts.loc[warsaw_districts['warsaw_district'] == district, 'geoPrecision'].idxmin()\n",
        "#             print(district+':\\t', district_to_drop_idx, '\\n')\n",
        "            warsaw_districts = warsaw_districts.drop(district_to_drop_idx).reset_index(drop=True)  \n",
        "            \n",
        "    return warsaw_districts"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_FDozWjxKZF"
      },
      "source": [
        "def get_cities():\n",
        "    # Description:\n",
        "    #  - sparql query is constructed for different types of cities: city with powiat rights ('Q925381'), urban municipality of Poland (Q2616791), and the second for \"regular\" city ('Q515')\n",
        "    # Problems:\n",
        "    #   1) some cities have more than one set of coordinates\n",
        "    #   2) filter within masovian voivodeship\n",
        "    # Solutions:\n",
        "    #   1) retain only the one with best precision (lowest value)\n",
        "    #   2) we can use .contains method from geopandas package, check the crs of Point from wikidata (https://www.kaggle.com/alexisbcook/proximity-analysis)\n",
        "    # To do:\n",
        "    #   1) check this approach\n",
        "      \n",
        "    # Get both types of cities: cities with powiat rights (Q925381), urban municipality of Poland (Q2616791), and the the \"regular\" cities (Q515)\n",
        "    # https://docs.python.org/3/reference/lexical_analysis.html#f-strings\n",
        "    # https://query.wikidata.org/#SELECT%20%3Fcity%20%3FcityLabel%20%3Flatitude%20%3Flongitude%20%3FgeoPrecision%20%3Fcoord%0AWHERE%20%7B%0A%20%20%3Fcity%20%20wdt%3AP31%20wd%3AQ925381%3B%0A%20%20%20%20%20%20%20%20%20wdt%3AP17%20wd%3AQ36%3B%0A%20%20%20%20%20%20%20%20%20%23wdt%3AP131%20wd%3AQ54169%3B%0A%20%20%20%20%20%20%20%20%20p%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20psv%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLatitude%20%3Flatitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLongitude%20%3Flongitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoPrecision%20%20%3FgeoPrecision%3B%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D%3B%0A%20%20%20%20%20%20%20%20%20ps%3AP625%20%3Fcoord%20%0A%20%20%20%20%20%20%20%20%20%5D%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22pl%22.%20%7D%0A%7D\n",
        "    # https://query.wikidata.org/#SELECT%20%3Fcity%20%3FcityLabel%20%3Flatitude%20%3Flongitude%20%3FgeoPrecision%20%3Fcoord%0AWHERE%20%7B%0A%20%20%3Fcity%20%20wdt%3AP31%20wd%3AQ515%3B%0A%20%20%20%20%20%20%20%20%20wdt%3AP17%20wd%3AQ36%3B%0A%20%20%20%20%20%20%20%20%20%23wdt%3AP131%20wd%3AQ54169%3B%0A%20%20%20%20%20%20%20%20%20p%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20psv%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLatitude%20%3Flatitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLongitude%20%3Flongitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoPrecision%20%20%3FgeoPrecision%3B%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D%3B%0A%20%20%20%20%20%20%20%20%20ps%3AP625%20%3Fcoord%20%0A%20%20%20%20%20%20%20%20%20%5D%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22pl%22.%20%7D%0A%7D\n",
        "    cities_all = pd.DataFrame()\n",
        "    url = 'https://query.wikidata.org/sparql'\n",
        "    data = pd.DataFrame()\n",
        "    types_of_city = {'city with powiat rights': 'Q925381', 'urban municipality of Poland ': 'Q2616791', 'city': 'Q515'}\n",
        "    for type_of_city, type_of_city_sparql in types_of_city.items():\n",
        "#         print('\\n\\nCities of type \\'' + type_of_city + '\\' (' + str(type_of_city_sparql) + '):')\n",
        "        query = f''' \n",
        "            SELECT ?city ?cityLabel ?latitude ?longitude ?geoPrecision ?coord\n",
        "            WHERE {{\n",
        "              ?city  wdt:P31 wd:{type_of_city_sparql};\n",
        "                     wdt:P17 wd:Q36;\n",
        "                     #wdt:P131 wd:Q54169;\n",
        "                     p:P625 [\n",
        "                             psv:P625 [\n",
        "                                       wikibase:geoLatitude ?latitude ;\n",
        "                                       wikibase:geoLongitude ?longitude ;\n",
        "                                       wikibase:geoPrecision  ?geoPrecision;      \n",
        "                                      ];\n",
        "                     ps:P625 ?coord \n",
        "                     ]\n",
        "              SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"pl\". }}\n",
        "            }}\n",
        "            '''\n",
        "        r = requests.get(url, params = {'format': 'json', 'query': query})\n",
        "        data = r.json()\n",
        "\n",
        "        \n",
        "        # Convert json to dataframe\n",
        "        cities = []\n",
        "        for item in data['results']['bindings']:\n",
        "#             print(item,'\\n')    \n",
        "            cities.append(OrderedDict(\n",
        "            {\n",
        "                'city':             item['cityLabel']['value'].lower(),\n",
        "                'latitude':         float(item['latitude']['value']),        \n",
        "                'longitude':        float(item['longitude']['value']),                    \n",
        "                'geoPrecision':     float(item['geoPrecision']['value']),                                \n",
        "                'wikidata_item_id': item['city']['value'].split('/')[-1]\n",
        "            }))\n",
        "        cities = pd.DataFrame(cities).sort_values(by=['city']).reset_index(drop=True)\n",
        "#         print('Number of cities of type', type_of_city+':', len(cities))\n",
        "\n",
        "        \n",
        "        # Find those city names that have multiple instaces:\n",
        "        #   - those with the same wikidata_item_id are the same city with multiple coordinate sets - retain only the set with best (lowest) geoPrecision,\n",
        "        #   - those with different wikidata_item_id are different cities and should not be considered with the following procedure.\n",
        "        # https://stackoverflow.com/questions/55360314/pandas-groupby-take-counts-greater-than-1\n",
        "        cities_with_the_same_name_and_wikidataItemId = cities.loc[cities.groupby(['city', 'wikidata_item_id'])['geoPrecision'].transform('count') > 1].reset_index(drop=True) # cities.loc[cities.duplicated(subset=['city', 'wikidata_item_id'], keep=False)].reset_index(drop=True)\n",
        "#         print('Cities with the same name and the same wikidata_item_id:', len(cities_with_the_same_name_and_wikidataItemId))\n",
        "        \n",
        "    \n",
        "        # If multiple instances of any city exist, retain only the one with the best precision (lowest value) \n",
        "#         print('Cities with multiple instances:', len(cities_with_the_same_name_and_wikidataItemId), '\\n')\n",
        "        for city in cities_with_the_same_name_and_wikidataItemId['city'].unique():\n",
        "#             print(city)\n",
        "            city_to_retain_idx = cities_with_the_same_name_and_wikidataItemId.loc[cities_with_the_same_name_and_wikidataItemId['city'] == city, 'geoPrecision'].idxmin()        \n",
        "            cities_to_drop = cities_with_the_same_name_and_wikidataItemId.loc[(cities_with_the_same_name_and_wikidataItemId['city'] == city) & (cities_with_the_same_name_and_wikidataItemId.index != city_to_retain_idx)].index\n",
        "#             print('city:', city, '\\nindex and geoPrecision of instance to retain:', city_to_retain_idx, cities_with_the_same_name_and_wikidataItemId.loc[city_to_retain_idx, 'geoPrecision'], '\\nindices and geoPrecisions of instances to drop:\\n', tabulate(cities_with_the_same_name_and_wikidataItemId.loc[cities_to_drop, ['geoPrecision']], tablefmt='psql'))\n",
        "            cities = cities.drop(cities_to_drop).reset_index(drop=True)\n",
        "#         print('Number of cities with multiple instances of given cities after cleaning:', len(cities_with_the_same_name_and_wikidataItemId))\n",
        "\n",
        "\n",
        "        # Append to cities_all\n",
        "        cities_all = pd.concat([cities_all, cities], axis = 0).sort_values(by=['city']).reset_index(drop=True)\n",
        "#         print('Number of cities of type', type_of_city, 'after cleaning duplicate coordinates:', len(cities))\n",
        "\n",
        "    \n",
        "#     print('Number of all cities:', len(cities_all), '\\n', '#'*72)\n",
        "    return cities_all"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iS1TurYI9hM"
      },
      "source": [
        "def get_counties():\n",
        "    # Description:\n",
        "    #  - sparql query is constructed for counties ('Q247073'),\n",
        "      \n",
        "    # Get both types of cities: cities with powiat rights (Q925381), urban municipality of Poland (Q2616791), and the the \"regular\" cities (Q515)\n",
        "    # https://docs.python.org/3/reference/lexical_analysis.html#f-strings\n",
        "    # https://query.wikidata.org/#SELECT%20%3Fcity%20%3FcityLabel%20%3Flatitude%20%3Flongitude%20%3FgeoPrecision%20%3Fcoord%0AWHERE%20%7B%0A%20%20%3Fcity%20%20wdt%3AP31%20wd%3AQ247073%3B%0A%20%20%20%20%20%20%20%20%20wdt%3AP17%20wd%3AQ36%3B%0A%20%20%20%20%20%20%20%20%20wdt%3AP131%20wd%3AQ54169%3B%0A%20%20%20%20%20%20%20%20%20p%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20psv%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLatitude%20%3Flatitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLongitude%20%3Flongitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoPrecision%20%20%3FgeoPrecision%3B%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D%3B%0A%20%20%20%20%20%20%20%20%20ps%3AP625%20%3Fcoord%20%0A%20%20%20%20%20%20%20%20%20%5D%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22pl%22.%20%7D%0A%7D\n",
        "    cities_all = pd.DataFrame()\n",
        "    url = 'https://query.wikidata.org/sparql'\n",
        "    query = '''\n",
        "    SELECT ?county ?countyLabel ?latitude ?longitude ?geoPrecision ?coord\n",
        "    WHERE {\n",
        "      ?county  wdt:P31 wd:Q247073;\n",
        "            wdt:P17 wd:Q36;\n",
        "            wdt:P131 wd:Q54169;\n",
        "            p:P625 [\n",
        "                    psv:P625 [\n",
        "                              wikibase:geoLatitude ?latitude ;\n",
        "                              wikibase:geoLongitude ?longitude ;\n",
        "                              wikibase:geoPrecision  ?geoPrecision;      \n",
        "                              ];\n",
        "            ps:P625 ?coord \n",
        "            ]\n",
        "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"pl\". }\n",
        "    }\n",
        "    '''\n",
        "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
        "#     print(r.json())\n",
        "    data = r.json()\n",
        "\n",
        "    # convert json to dataframe\n",
        "    counties = []\n",
        "    for item in data['results']['bindings']:\n",
        "#         print(item,'\\n')    \n",
        "        counties.append(OrderedDict(\n",
        "        {\n",
        "            'county':           item['countyLabel']['value'].lower(),\n",
        "            'latitude':         float(item['latitude']['value']),        \n",
        "            'longitude':        float(item['longitude']['value']),                    \n",
        "            'geoPrecision':     float(item['geoPrecision']['value']),                                \n",
        "            'wikidata_item_id': item['county']['value'].split('/')[-1]\n",
        "        }))\n",
        "    \n",
        "    counties = pd.DataFrame(counties).sort_values(by=['county'])\n",
        "      \n",
        "    return counties"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqZDj2pQ8JS6"
      },
      "source": [
        "dfCities=get_cities()\n",
        "dfCounties=get_counties()\n",
        "dfVoivodeships=get_voivodeships()\n",
        "dfWarsawDistricts=get_warsaw_districts()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIAiPJZpdldk"
      },
      "source": [
        "def return_coordinates(place,type):\n",
        "    '''\n",
        "    Returns coordinates of the place.\n",
        "        The place must be the name (in polish) of voivodeship in Poland, city, or the district of Warsaw.\n",
        "    '''\n",
        "    \n",
        "    coordinates = [None, None]\n",
        "    place = place.lower()\n",
        "    if type=='V':\n",
        "      print('voivodeships',place)\n",
        "\n",
        "      try:\n",
        "          voivodeships = get_voivodeships()\n",
        "          coordinates_df = voivodeships.loc[voivodeships['voivodeship'].str.contains(place) == True, ['latitude', 'longitude']]\n",
        "          coordinates = coordinates_df.values.tolist()[0]       \n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "    elif type=='D':\n",
        "      print('warsaw districts',place)\n",
        "      try:\n",
        "          counties = get_counties()\n",
        "          coordinates_df = counties.loc[counties['warsaw_district'].str.contains(place) == True, ['latitude', 'longitude']]\n",
        "          coordinates = coordinates_df.values.tolist()[0]\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "    elif type=='C':   \n",
        "      print('cities',place)\n",
        "      try:\n",
        "          cities = get_cities()\n",
        "          coordinates_df = cities.loc[cities['city'].str.contains(place) == True, ['latitude', 'longitude']]\n",
        "          coordinates = coordinates_df.values.tolist()[0]\n",
        "      except Exception as e:\n",
        "          print(e)   \n",
        "    print(coordinates)\n",
        "    return coordinates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyCylFst7j1X"
      },
      "source": [
        "def makeDataFrame(file):\n",
        "    dfMazowieckie=pd.read_csv(file,index_col=0)\n",
        "    concat=dfMazowieckie\n",
        "    concat['powierzchnia_corr'] = concat['powierzchnia'].apply(lambda x: toNum1(x))\n",
        "    concat['powierzchniaDzialki_corr'] = concat['powierzchniaDzialki'].apply(lambda x: toNum2(x))\n",
        "    concat['cena_corr'] = concat['cena'].apply(lambda x: toNum2(x))\n",
        "    concat['rokBudowy_corr'] = concat['rokBudowy'].apply(lambda x: toNum3(x))\n",
        "    concat['cena/m'] = concat['cena_corr'] / concat['powierzchnia_corr']\n",
        "    concat['lPieter_crr'] = concat['lPieter'].apply(lambda x: pietra(x))\n",
        "    concat = concat[concat['powierzchnia_corr'] > 0]\n",
        "    concat = concat[concat['cena_corr'] > 0]\n",
        "    concat['lPokoi'] = concat['lPokoi'].apply(lambda x: toNum3(x))\n",
        "    concat['districts']=concat['dzielnica'].apply(lambda x: x.split()[4])\n",
        "    cities_corr=concat['dzielnica'].apply(lambda x: cities(x))\n",
        "    concat['cities_corr']=cities_corr\n",
        "    region_corr=concat['dzielnica'].apply(lambda x: region(x))\n",
        "    concat['region_corr']=region_corr\n",
        "    concat_dropped = concat.drop(['dzielnica', 'powierzchnia', 'powierzchniaDzialki', 'lPieter', 'cena', 'cena_corr',], axis=1)\n",
        "    concat_dropped['rokBudowy'] = concat_dropped['rokBudowy'].replace(to_replace=0, value=1990)\n",
        "    concat_dropped['rokBudowy'] = concat_dropped['rokBudowy'].astype('int')\n",
        "    concat_dropped = concat_dropped.fillna(0)\n",
        "    concat_dropped = concat_dropped[concat_dropped['cena/m'] < 20000]\n",
        "    concat_dropped['cena/m'].hist(bins=200)\n",
        "\n",
        "    #concat_dropped_dumm = pd.get_dummies(concat_dropped, columns=['rodzajZabudowy', 'materialBudynku', 'stanWykonczenia', 'okna', 'rynek',\n",
        "    #                                       'cities_corr','districts','region_corr'])\n",
        "    \n",
        "    cityData=concat_dropped.cities_corr.apply(lambda x: funCities(x))\n",
        "    locationCities=locCities(cityData)\n",
        "    districtsData=concat_dropped.region_corr.apply(lambda x: funDistricts(x))\n",
        "    locationDistricts=locCities(districtsData)\n",
        "    countyData=concat_dropped.districts.apply(lambda x: funCounties(x))\n",
        "    locationCounty=locCounties(countyData)\n",
        "\n",
        "    concat_dropped_reset=concat_dropped.reset_index().drop(['index'],axis=1)\n",
        "    locations= pd.concat([locationCities,locationDistricts,locationCounty], axis=1)\n",
        "    concat_dropped_reset['locationX']=locations.apply(selectLocationX,axis=1)\n",
        "    concat_dropped_reset['locationY']=locations.apply(selectLocationY,axis=1)\n",
        "    concat_dropped_reset_drop = concat_dropped_reset.drop(['rokBudowy', 'districts', 'cities_corr', 'region_corr'], axis=1)\n",
        "    final = pd.get_dummies(concat_dropped_reset_drop, columns=['rodzajZabudowy', 'materialBudynku', 'stanWykonczenia', 'okna', 'rynek'])\n",
        "\n",
        "    return final"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAA1mSAY9P8O"
      },
      "source": [
        "def funCities(x):\n",
        "  rows=dfCities.loc[dfCities['city']==x.lower()]\n",
        "  precision=0\n",
        "  if rows.shape[0]==0:\n",
        "    return 0,0,100\n",
        "  elif rows.shape[0]==1:\n",
        "    longitude=rows.longitude.values\n",
        "    latitude=rows.latitude.values\n",
        "    precision=rows.geoPrecision.values\n",
        "    return longitude[0],latitude[0],precision[0]\n",
        "  elif rows.shape[0]>1:\n",
        "    prec1,prec2=rows.iloc[0,3],rows.iloc[1,3]\n",
        "    if prec1<prec2:\n",
        "      precision=prec1\n",
        "      longitude=rows.iloc[0,2]\n",
        "      latitude=rows.iloc[0,1]\n",
        "    else:\n",
        "      precision=prec2\n",
        "      longitude=rows.iloc[1,2]\n",
        "      latitude=rows.iloc[1,1]\n",
        "    return longitude,latitude,precision"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quM6ZeSO9UdN"
      },
      "source": [
        "def funDistricts(x):\n",
        "  rows=dfWarsawDistricts.loc[dfWarsawDistricts['warsaw_district']==x.lower()]\n",
        "  #print(x, ' ',rows.shape[0])\n",
        "  if rows.shape[0]==0:\n",
        "    return 0,0,100\n",
        "  elif rows.shape[0]==1:\n",
        "    longitude=rows.longitude.values\n",
        "    latitude=rows.latitude.values\n",
        "    precision=rows.geoPrecision.values\n",
        "    return longitude[0],latitude[0],precision[0]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "domiHiOr9R4d"
      },
      "source": [
        "def funCounties(x):\n",
        "  try:\n",
        "    rows=dfCounties.loc['powiat '+x.lower()== dfCounties['county']]\n",
        "  except Exception as e:\n",
        "    return e\n",
        "  #print(x, ' ',rows.shape[0])\n",
        "  if rows.shape[0]==0:\n",
        "    return 0,0,100\n",
        "  elif rows.shape[0]==1:\n",
        "    longitude=rows.longitude.values\n",
        "    latitude=rows.latitude.values\n",
        "    precision=rows.geoPrecision.values\n",
        "    return longitude[0],latitude[0],precision[0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW1CIMKJfS3d"
      },
      "source": [
        "def selectLocationX(x):\n",
        " # print(x[17],x[20],x[23])\n",
        "  if x[2]<min(x[5],x[8]):\n",
        "    #print('min 17',x[15],x[16])\n",
        "    return x[0]\n",
        "  elif x[5]<min(x[2],x[8]):\n",
        "    #print('min 20 ',x[18],x[19])\n",
        "    return x[3]\n",
        "  elif x[8]<min(x[2],x[5]):\n",
        "    #print('min 23 ',x[21],x[22])\n",
        "    return x[6]\n",
        "\n",
        "def selectLocationY(x):\n",
        " # print(x[17],x[20],x[23])\n",
        "  if x[2]<min(x[5],x[8]):\n",
        "    #print('min 17',x[15],x[16])\n",
        "    return x[1]\n",
        "  elif x[5]<min(x[2],x[8]):\n",
        "    #print('min 20 ',x[18],x[19])\n",
        "    return x[4]\n",
        "  elif x[8]<min(x[2],x[5]):\n",
        "    #print('min 23 ',x[21],x[22])\n",
        "    return x[7]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmOjGx4Z7lbR"
      },
      "source": [
        "filename='/content/drive/My Drive/domy mazowieckie/dfMazowieckie.csv'\n",
        "dfCities=get_cities()\n",
        "dfCounties=get_counties()\n",
        "dfVoivodeships=get_voivodeships()\n",
        "dfWarsawDistricts=get_warsaw_districts()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "hl-GYCGD7mwf",
        "outputId": "0049f820-3947-4be6-b9a5-e92b35d4e905"
      },
      "source": [
        "final=makeDataFrame(filename)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMZjk9pN9LDs"
      },
      "source": [
        "cityData=concat_dropped.cities_corr.apply(lambda x: funCities(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekjsR841YLxw"
      },
      "source": [
        "def locCities(cityData):\n",
        "  locationCities=[]\n",
        "  for data in cityData:\n",
        "    locationCities.append(data)\n",
        "  locationCities=pd.DataFrame(np.array(locationCities),columns=['cityX','cityY','cityGeo'])\n",
        "  return locationCities"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC17dlYC0uBq"
      },
      "source": [
        "districtsData=concat_dropped.region_corr.apply(lambda x: funDistricts(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUcjJeWX8eSY"
      },
      "source": [
        "locationDistricts=[]\n",
        "for data in districtsData:\n",
        "  locationDistricts.append(data)\n",
        "locationDistricts=pd.DataFrame(np.array(locationDistricts),columns=['distX','distY','distGeo'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inMBcXC-WSQw"
      },
      "source": [
        "def locDistricts(districtsData):\n",
        "  locationCities=[]\n",
        "  for data in cityData:\n",
        "    locationDistricts.append(data)\n",
        "  locationDistricts=pd.DataFrame(np.array(locationDistricts),columns=['cityX','cityY','cityGeo'])\n",
        "  return locationDistricts"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1iFt0wMMo6y"
      },
      "source": [
        "countyData=concat_dropped.districts.apply(lambda x: funCounties(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a87ctAciMk9u"
      },
      "source": [
        "def locCounties(countyData):\n",
        "  locationCounty=[]\n",
        "  for data in countyData:\n",
        "    locationCounty.append(data)\n",
        "  locationCounty=pd.DataFrame(np.array(locationCounty),columns=['countyX','countyY','countyGeo'])\n",
        "  return locationCounty"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyxiHlcoBw3U"
      },
      "source": [
        "concat_dropped_reset=concat_dropped.reset_index().drop(['index'],axis=1)\n",
        "locations= pd.concat([locationCities,locationDistricts,locationCounty], axis=1)\n",
        "concat_dropped_reset['locationX']=locations.apply(selectLocationX,axis=1)\n",
        "concat_dropped_reset['locationY']=locations.apply(selectLocationY,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "jNpvfov_dwcc",
        "outputId": "d97c29c7-1443-4584-e895-f37f22549b2f"
      },
      "source": [
        "concat_dropped_reset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lPokoi</th>\n",
              "      <th>rodzajZabudowy</th>\n",
              "      <th>materialBudynku</th>\n",
              "      <th>rokBudowy</th>\n",
              "      <th>stanWykonczenia</th>\n",
              "      <th>okna</th>\n",
              "      <th>rynek</th>\n",
              "      <th>powierzchnia_corr</th>\n",
              "      <th>powierzchniaDzialki_corr</th>\n",
              "      <th>rokBudowy_corr</th>\n",
              "      <th>cena/m</th>\n",
              "      <th>lPieter_crr</th>\n",
              "      <th>districts</th>\n",
              "      <th>cities_corr</th>\n",
              "      <th>region_corr</th>\n",
              "      <th>locationX</th>\n",
              "      <th>locationY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>wolnostojÄ…cy</td>\n",
              "      <td>cegÅ‚a</td>\n",
              "      <td>2019</td>\n",
              "      <td>do wykoÅ„czenia</td>\n",
              "      <td>0</td>\n",
              "      <td>wtÃ³rny</td>\n",
              "      <td>320.00</td>\n",
              "      <td>1000</td>\n",
              "      <td>2019</td>\n",
              "      <td>6062.503125</td>\n",
              "      <td>1</td>\n",
              "      <td>Warszawa</td>\n",
              "      <td>Warszawa</td>\n",
              "      <td>WesoÅ‚a</td>\n",
              "      <td>21.223696</td>\n",
              "      <td>52.245856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>beton komÃ³rkowy</td>\n",
              "      <td>2021</td>\n",
              "      <td>do wykoÅ„czenia</td>\n",
              "      <td>plastikowe</td>\n",
              "      <td>pierwotny</td>\n",
              "      <td>154.00</td>\n",
              "      <td>750</td>\n",
              "      <td>2021</td>\n",
              "      <td>5186.363636</td>\n",
              "      <td>0</td>\n",
              "      <td>grodziski</td>\n",
              "      <td>MilanÃ³wek</td>\n",
              "      <td></td>\n",
              "      <td>20.665400</td>\n",
              "      <td>52.124300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>wolnostojÄ…cy</td>\n",
              "      <td>0</td>\n",
              "      <td>1950</td>\n",
              "      <td>do remontu</td>\n",
              "      <td>0</td>\n",
              "      <td>wtÃ³rny</td>\n",
              "      <td>80.00</td>\n",
              "      <td>2356</td>\n",
              "      <td>1950</td>\n",
              "      <td>5612.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>nowodworski</td>\n",
              "      <td>Nowy</td>\n",
              "      <td></td>\n",
              "      <td>20.683333</td>\n",
              "      <td>52.433333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>bliÅºniak</td>\n",
              "      <td>silikat</td>\n",
              "      <td>2022</td>\n",
              "      <td>do wykoÅ„czenia</td>\n",
              "      <td>plastikowe</td>\n",
              "      <td>pierwotny</td>\n",
              "      <td>152.91</td>\n",
              "      <td>220</td>\n",
              "      <td>2022</td>\n",
              "      <td>4250.866523</td>\n",
              "      <td>1</td>\n",
              "      <td>piaseczyÅ„ski</td>\n",
              "      <td>Nowa</td>\n",
              "      <td></td>\n",
              "      <td>21.016667</td>\n",
              "      <td>52.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>wolnostojÄ…cy</td>\n",
              "      <td>pustak</td>\n",
              "      <td>2020</td>\n",
              "      <td>stan surowy otwarty</td>\n",
              "      <td>brak</td>\n",
              "      <td>pierwotny</td>\n",
              "      <td>106.00</td>\n",
              "      <td>960</td>\n",
              "      <td>2020</td>\n",
              "      <td>2924.528302</td>\n",
              "      <td>0</td>\n",
              "      <td>pÅ‚ocki</td>\n",
              "      <td>SÅ‚upno</td>\n",
              "      <td></td>\n",
              "      <td>19.700000</td>\n",
              "      <td>52.550000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   lPokoi rodzajZabudowy  materialBudynku  ...  region_corr  locationX  locationY\n",
              "0       6   wolnostojÄ…cy            cegÅ‚a  ...       WesoÅ‚a  21.223696  52.245856\n",
              "1       5              0  beton komÃ³rkowy  ...               20.665400  52.124300\n",
              "2       3   wolnostojÄ…cy                0  ...               20.683333  52.433333\n",
              "3       4       bliÅºniak          silikat  ...               21.016667  52.066667\n",
              "4       4   wolnostojÄ…cy           pustak  ...               19.700000  52.550000\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMBtwULwnpio"
      },
      "source": [
        "concat = concat_dropped_reset.drop(['rokBudowy', 'districts', 'cities_corr', 'region_corr'], axis=1)\n",
        "concat_dumm = pd.get_dummies(concat, columns=['rodzajZabudowy', 'materialBudynku', 'stanWykonczenia', 'okna', 'rynek'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCUOXEGvoIbi",
        "outputId": "f643c5d9-6f03-4702-9d3c-93207a224771"
      },
      "source": [
        "concat_dumm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7823, 37)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "WLMLd9O9zf8S",
        "outputId": "bcce5859-c3be-4ac8-d523-23d4d0cd0e5c"
      },
      "source": [
        "concat_dumm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lPokoi</th>\n",
              "      <th>powierzchnia_corr</th>\n",
              "      <th>powierzchniaDzialki_corr</th>\n",
              "      <th>rokBudowy_corr</th>\n",
              "      <th>cena/m</th>\n",
              "      <th>lPieter_crr</th>\n",
              "      <th>locationX</th>\n",
              "      <th>locationY</th>\n",
              "      <th>rodzajZabudowy_0</th>\n",
              "      <th>rodzajZabudowy_bliÅºniak</th>\n",
              "      <th>rodzajZabudowy_dworek/paÅ‚ac</th>\n",
              "      <th>rodzajZabudowy_gospodarstwo</th>\n",
              "      <th>rodzajZabudowy_kamienica</th>\n",
              "      <th>rodzajZabudowy_szeregowiec</th>\n",
              "      <th>rodzajZabudowy_wolnostojÄ…cy</th>\n",
              "      <th>materialBudynku_0</th>\n",
              "      <th>materialBudynku_beton</th>\n",
              "      <th>materialBudynku_beton komÃ³rkowy</th>\n",
              "      <th>materialBudynku_cegÅ‚a</th>\n",
              "      <th>materialBudynku_drewno</th>\n",
              "      <th>materialBudynku_inne</th>\n",
              "      <th>materialBudynku_keramzyt</th>\n",
              "      <th>materialBudynku_pustak</th>\n",
              "      <th>materialBudynku_silikat</th>\n",
              "      <th>stanWykonczenia_0</th>\n",
              "      <th>stanWykonczenia_do remontu</th>\n",
              "      <th>stanWykonczenia_do wykoÅ„czenia</th>\n",
              "      <th>stanWykonczenia_do zamieszkania</th>\n",
              "      <th>stanWykonczenia_stan surowy otwarty</th>\n",
              "      <th>stanWykonczenia_stan surowy zamkniÄ™ty</th>\n",
              "      <th>okna_0</th>\n",
              "      <th>okna_aluminiowe</th>\n",
              "      <th>okna_brak</th>\n",
              "      <th>okna_drewniane</th>\n",
              "      <th>okna_plastikowe</th>\n",
              "      <th>rynek_pierwotny</th>\n",
              "      <th>rynek_wtÃ³rny</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>320.00</td>\n",
              "      <td>1000</td>\n",
              "      <td>2019</td>\n",
              "      <td>6062.503125</td>\n",
              "      <td>1</td>\n",
              "      <td>21.223696</td>\n",
              "      <td>52.245856</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>154.00</td>\n",
              "      <td>750</td>\n",
              "      <td>2021</td>\n",
              "      <td>5186.363636</td>\n",
              "      <td>0</td>\n",
              "      <td>20.665400</td>\n",
              "      <td>52.124300</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>80.00</td>\n",
              "      <td>2356</td>\n",
              "      <td>1950</td>\n",
              "      <td>5612.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>20.683333</td>\n",
              "      <td>52.433333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>152.91</td>\n",
              "      <td>220</td>\n",
              "      <td>2022</td>\n",
              "      <td>4250.866523</td>\n",
              "      <td>1</td>\n",
              "      <td>21.016667</td>\n",
              "      <td>52.066667</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>106.00</td>\n",
              "      <td>960</td>\n",
              "      <td>2020</td>\n",
              "      <td>2924.528302</td>\n",
              "      <td>0</td>\n",
              "      <td>19.700000</td>\n",
              "      <td>52.550000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   lPokoi  powierzchnia_corr  ...  rynek_pierwotny  rynek_wtÃ³rny\n",
              "0       6             320.00  ...                0             1\n",
              "1       5             154.00  ...                1             0\n",
              "2       3              80.00  ...                0             1\n",
              "3       4             152.91  ...                1             0\n",
              "4       4             106.00  ...                1             0\n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-tN-Z-L0dJ6"
      },
      "source": [
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KEHBeUP0JFb"
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "data_scaled = min_max_scaler.fit_transform(concat_dumm.values)\n",
        "df = pd.DataFrame(data_scaled ,columns=concat_dumm.columns.values)\n",
        "df  = df.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwdHWJuIotl4"
      },
      "source": [
        "#!pip install --upgrade pip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_Rghy5nwEK8"
      },
      "source": [
        "#!pip install tf-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdnxBmZV77y9",
        "outputId": "89e790c1-399c-4bee-950e-9f8acabca2c9"
      },
      "source": [
        "!pip install tensorflow_decision_forests"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_decision_forests\n",
            "  Downloading tensorflow_decision_forests-0.1.8-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.3 MB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.15.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (0.37.0)\n",
            "Requirement already satisfied: tensorflow~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (2.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.1.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.19.5)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (0.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.39.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.7.4.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (2.6.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (2.6.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.1.2)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (2.6.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow~=2.5->tensorflow_decision_forests) (1.5.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (1.34.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (0.4.5)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow~=2.5->tensorflow_decision_forests) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_decision_forests) (2018.9)\n",
            "Installing collected packages: tensorflow-decision-forests\n",
            "Successfully installed tensorflow-decision-forests-0.1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdsx6N2O791r",
        "outputId": "e170b6ea-5fed-4005-c17b-a75c9eb1edd0"
      },
      "source": [
        "!pip install wurlitzer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wurlitzer\n",
            "  Downloading wurlitzer-2.1.1-py2.py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: wurlitzer\n",
            "Successfully installed wurlitzer-2.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hks9GYwX8Anv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "8907a30b-7f48-40e6-aa02-4d1c5bfd86df"
      },
      "source": [
        "import tensorflow_decision_forests as tfdf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow as tfCore\n",
        "import math\n",
        "\n",
        "try:\n",
        "  from wurlitzer import sys_pipes\n",
        "except:\n",
        "  from colabtools.googlelog import CaptureLog as sys_pipes\n",
        "\n",
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-a6b666e9fc05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0m__author__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Mathieu Guillame-Bert\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpy_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbase_tracking\u001b[0m  \u001b[0;31m# pylint: disable=g-direct-tensorflow-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspector\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minspector_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/tensorflow/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myggdrasil_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_spec_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myggdrasil_decision_forests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabstract_learner_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/tensorflow/ops/training/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_op_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path_to_datafile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training.so\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_op_library\u001b[0;34m(library_filename)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0munable\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpython\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0mlib_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_LoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     wrappers = _pywrap_python_op_gen.GetPythonWrappers(\n",
            "\u001b[0;31mNotFoundError\u001b[0m: /usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/tensorflow/ops/training/training.so: undefined symbol: _ZN10tensorflow11GetNodeAttrERKNS_9AttrSliceEN4absl14lts_2020_09_2311string_viewEPSs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrtkVoZ_qrLd"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-gV30Xwqh-6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r2Ey0088TkP"
      },
      "source": [
        "# Check the version of TensorFlow Decision Forests\n",
        "print(\"Found TensorFlow Decision Forests v\" + tfdf.__version__)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Znol7CLscj"
      },
      "source": [
        "def split_dataset(dataset, test_ratio=0.30):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s_rESer9MtT"
      },
      "source": [
        "train_ds_pd, test_ds_pd = split_dataset(concat_dumm)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rXpRB01LBjs"
      },
      "source": [
        "alternatywna macierz z min max scaller"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdpW8HNxK8G6"
      },
      "source": [
        "train_ds_pd, test_ds_pd = split_dataset(df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXtzXfGZzxI1"
      },
      "source": [
        "from tensorflow_decision_forests.tensorflow import core as tf_core"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH481NYO93aS"
      },
      "source": [
        "#train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
        "Task = tf_core.Task\n",
        "train_ds=tfdf.keras.pd_dataframe_to_tf_dataset(\n",
        "    train_ds_pd,\n",
        "    label='cena/m',\n",
        "    task=Task.REGRESSION\n",
        ")\n",
        "\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
        "    test_ds_pd,\n",
        "    label='cena/m',\n",
        "    task=Task.REGRESSION\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRJ0vI419dN2"
      },
      "source": [
        "# A classical but slighly more complex model.\n",
        "model_tune = tfdf.keras.GradientBoostedTreesModel(\n",
        "    task=Task.REGRESSION,num_trees=2000000, growing_strategy=\"BEST_FIRST_GLOBAL\", max_depth=2000000)\n",
        "model_tune.compile(\n",
        "    metrics=['mse',\"mae\",'acc'])\n",
        "model_tune.fit(train_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz6V8srF2vJS"
      },
      "source": [
        "evaluation = model_tune.evaluate(train_ds, return_dict=True)\n",
        "print()\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print('alsolute ',f\"{name}: {value:.4f}\")\n",
        "  print('relative ',f\"{name}: {100*value/df['cena/m'].mean():.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1C4rLy86jMB"
      },
      "source": [
        "evaluation = model_tune.evaluate(test_ds, return_dict=True)\n",
        "print()\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print('alsolute ',f\"{name}: {value:.4f}\")\n",
        "  print('relative ',f\"{name}: {100*value/df['cena/m'].mean():.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek6i-mn0DcyM"
      },
      "source": [
        "model_tune.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}