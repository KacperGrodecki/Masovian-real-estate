{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mazowieckie_colab_rysunki i analiza.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkaTF1hEyr+9Xx4mSaAlPx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KacperGrodecki/nieruchomosci-mazowieckie/blob/0.0.4/mazowieckie_colab_rysunki_i_analiza.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoyxUX4T7Yoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e12034-a9f1-4ff8-c1da-910da606defd"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import svm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(7)\n",
        "from google.colab import drive\n",
        "import seaborn as sns\n",
        "drive.mount('/content/drive')\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "#from otoDomScraper import daneDomu\n",
        "#from random import randrange\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statistics\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn import preprocessing\n",
        "from IPython.display import Javascript\n",
        "import requests\n",
        "from collections import OrderedDict\n",
        "import seaborn as sns"
      ],
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaSkJkDn7htz"
      },
      "source": [
        "def toNum2(txt):\n",
        "    if type(txt) is int:\n",
        "        return txt\n",
        "    elif (type(txt) is str):\n",
        "        digs = re.findall(r'\\d+', txt)\n",
        "        if len(digs) == 1:\n",
        "            return int(digs[0])\n",
        "        elif len(digs) == 2:\n",
        "            return 1000 * int(digs[0]) + int(digs[1])\n",
        "        elif len(digs) == 3:\n",
        "            return 1000000 * int(digs[0]) + 1000 * int(digs[1]) + int(digs[0])\n",
        "\n",
        "    #   return int(digs)\n",
        "\n",
        "\n",
        "def toNum1(txt):\n",
        "    if type(txt) is str:\n",
        "        digs = re.findall(r'\\d+', txt)\n",
        "        if len(digs) == 1:\n",
        "            return int(digs[0])\n",
        "        elif len(digs) == 2 and (txt[1] != ' '):\n",
        "            return int(digs[0]) + 0.01 * int(digs[1])\n",
        "        elif len(digs) == 3:\n",
        "            return 1000 * int(digs[0]) + int(digs[1]) + 0.001 * int(digs[2])\n",
        "        elif (type(txt) is str) and (txt[1] == ' '):\n",
        "            digs = re.findall(r'\\d+', txt)\n",
        "            return 1000 * int(digs[0]) + int(digs[1])\n",
        "    else:\n",
        "        return txt\n",
        "\n",
        "\n",
        "def toNum3(txt):\n",
        "    if type(txt) == int:\n",
        "        return txt\n",
        "    return int(re.findall(r'\\d+', txt)[0])\n",
        "\n",
        "def pietra(txt):\n",
        "    if type(txt) is str:\n",
        "        if '0' in txt:\n",
        "            return 0\n",
        "        if '1' in txt:\n",
        "            return 1\n",
        "        elif '2' in txt:\n",
        "            return 2\n",
        "        elif '3' in txt:\n",
        "            return 3\n",
        "        elif 'parterowy' in txt:\n",
        "            return 0\n",
        "    else:\n",
        "        return txt\n",
        "\n",
        "def cities(x):\n",
        "    dist=x.split()[4]\n",
        "    #city=x.split()[5]\n",
        "    if dist=='warszawski':\n",
        "        return x.split()[6]\n",
        "    elif dist in ['Warszawa','Radom','PÅ‚ock','Siedlce']:\n",
        "        return dist\n",
        "    else:\n",
        "        try:\n",
        "            return x.split()[5]\n",
        "        except:\n",
        "            return 'unknown'\n",
        "\n",
        "def region(x):\n",
        "    if x.split()[4]=='Warszawa':\n",
        "        try:\n",
        "            return x.split()[5]\n",
        "        except:\n",
        "            return ''\n",
        "    else:\n",
        "        return ''"
      ],
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz6yc0BqdG-c"
      },
      "source": [
        "#code written by Maciej Kozubal",
        "def get_voivodeships():\n",
        "    # problem - too many voivodeships, historical ones are mixed together\n",
        "    # solution - just cut the list after 16-th item\n",
        "    \n",
        "    # request voivodeships of poland(wd:Q36),\n",
        "    # cut after 16 voivodeships, the rest are historical ones\n",
        "    # https://query.wikidata.org/#%20%20%20%20SELECT%20%3Fvoivodeship%20%3FvoivodeshipLabel%20%3Flatitude%20%3Flongitude%20%3Fadmininistrative_teritorial_entity%0A%20%20%20%20WHERE%20%7B%0A%20%20%20%20%20%20%3Fvoivodeship%20wdt%3AP31%20wd%3AQ150093%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wdt%3AP131%20%3Fadmininistrative_teritorial_entity%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20p%3AP625%2Fpsv%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLatitude%20%3Flatitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLongitude%20%3Flongitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D.%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20FILTER%28%3Fadmininistrative_teritorial_entity%20%3D%20wd%3AQ36%29.%0A%20%20%20%20%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22pl%22.%20%7D%0A%20%20%20%20%7D%0A%20%20%20%20ORDER%20BY%20DESC%28%3Fvoivodeship%29%0A%20%20%20%20LIMIT%2016%0A\n",
        "    url = 'https://query.wikidata.org/sparql'\n",
        "    query = '''\n",
        "    SELECT ?voivodeship ?voivodeshipLabel ?latitude ?longitude ?admininistrative_teritorial_entity\n",
        "    WHERE {\n",
        "      ?voivodeship wdt:P31 wd:Q150093;\n",
        "                   wdt:P131 ?admininistrative_teritorial_entity;\n",
        "                   p:P625/psv:P625 [\n",
        "                       wikibase:geoLatitude ?latitude ;\n",
        "                       wikibase:geoLongitude ?longitude ;\n",
        "                   ].               \n",
        "      FILTER(?admininistrative_teritorial_entity = wd:Q36).\n",
        "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"pl\". }\n",
        "    }\n",
        "    ORDER BY DESC(?voivodeship)\n",
        "    LIMIT 16\n",
        "    '''\n",
        "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
        "    data = r.json()\n",
        "\n",
        "    # convert json to dataframe\n",
        "    voivodeships = []\n",
        "    for item in data['results']['bindings']:\n",
        "        voivodeships.append(OrderedDict(\n",
        "        {\n",
        "            'voivodeship':      item['voivodeshipLabel']['value'].lower(),\n",
        "            'latitude':         float(item['latitude']['value']),        \n",
        "            'longitude':        float(item['longitude']['value']),                    \n",
        "            'wikidata_item_id': item['voivodeship']['value'].split('/')[-1]\n",
        "        }))\n",
        "    #     print(item,'\\n')    \n",
        "    return pd.DataFrame(voivodeships)\n"
      ],
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnwWwv4vdeob"
      },
      "source": [
        "#code written by Maciej Kozubal",
        "def get_warsaw_districts():\n",
        "    # problem  - some districts have two sets of coordinates which differ slighlty\n",
        "    # solution - drop the one with worse precision (larger value), this seems to be consistent with the wikipedia data\n",
        "    # to do    - the above is not true for ['Wola'], change it\n",
        "    \n",
        "    # https://query.wikidata.org/#SELECT%20%3Fdistrict_of_Warsaw%20%3Fdistrict_of_WarsawLabel%20%3Flat%20%3Flon%20%3FgeoPrecision%20%0AWHERE%20%7B%0A%20%20%3Fdistrict_of_Warsaw%20%20wdt%3AP31%20wd%3AQ4286337%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wdt%3AP17%20wd%3AQ36%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wdt%3AP131%20wd%3AQ270%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20p%3AP625%2Fpsv%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLatitude%20%3Flat%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLongitude%20%3Flon%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoPrecision%20%20%3FgeoPrecision%3B%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22pl%22.%20%7D%0A%7D\n",
        "    url = 'https://query.wikidata.org/sparql'\n",
        "    query = '''\n",
        "    SELECT ?warsaw_district ?warsaw_districtLabel ?latitude ?longitude ?geoPrecision \n",
        "    WHERE {\n",
        "      ?warsaw_district  wdt:P31 wd:Q4286337;\n",
        "                           wdt:P17 wd:Q36;\n",
        "                           wdt:P131 wd:Q270;\n",
        "                           p:P625/psv:P625 [\n",
        "                               wikibase:geoLatitude ?latitude ;\n",
        "                               wikibase:geoLongitude ?longitude ;\n",
        "                               wikibase:geoPrecision  ?geoPrecision;                                       \n",
        "                           ]\n",
        "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"pl\". }\n",
        "    }\n",
        "    ORDER BY ASC(?warsaw_districtLabel)\n",
        "    '''\n",
        "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
        "#     print(r.json())\n",
        "    data = r.json()\n",
        "\n",
        "    # convert json to dataframe\n",
        "    warsaw_districts = []\n",
        "    for item in data['results']['bindings']:\n",
        "#         print(item,'\\n')    \n",
        "        warsaw_districts.append(OrderedDict(\n",
        "        {\n",
        "            'warsaw_district':  item['warsaw_districtLabel']['value'].lower(),\n",
        "            'latitude':         float(item['latitude']['value']),        \n",
        "            'longitude':        float(item['longitude']['value']),                    \n",
        "            'geoPrecision':     float(item['geoPrecision']['value']),                                \n",
        "            'wikidata_item_id': item['warsaw_district']['value'].split('/')[-1]\n",
        "        }))\n",
        "    \n",
        "    warsaw_districts = pd.DataFrame(warsaw_districts).sort_values(by=['warsaw_district'])\n",
        "    \n",
        "    # if duplicate warsaw districts exist, take the one with better precision (lower value), do the opposite in case of 'Wola' \n",
        "    for district in warsaw_districts['warsaw_district']:\n",
        "        if np.sum(warsaw_districts['warsaw_district'] == district) > 1: # duplicate district found\n",
        "            if district != 'wola':            \n",
        "                district_to_drop_idx = warsaw_districts.loc[warsaw_districts['warsaw_district'] == district, 'geoPrecision'].idxmax()\n",
        "            elif district == 'wola':\n",
        "                district_to_drop_idx = warsaw_districts.loc[warsaw_districts['warsaw_district'] == district, 'geoPrecision'].idxmin()\n",
        "#             print(district+':\\t', district_to_drop_idx, '\\n')\n",
        "            warsaw_districts = warsaw_districts.drop(district_to_drop_idx).reset_index(drop=True)  \n",
        "            \n",
        "    return warsaw_districts"
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_FDozWjxKZF"
      },
      "source": [
        "#code written by Maciej Kozubal",
        "def get_cities():\n",
        "    # Description:\n",
        "    #  - sparql query is constructed for different types of cities: city with powiat rights ('Q925381'), urban municipality of Poland (Q2616791), and the second for \"regular\" city ('Q515')\n",
        "    # Problems:\n",
        "    #   1) some cities have more than one set of coordinates\n",
        "    #   2) filter within masovian voivodeship\n",
        "    # Solutions:\n",
        "    #   1) retain only the one with best precision (lowest value)\n",
        "    #   2) we can use .contains method from geopandas package, check the crs of Point from wikidata (https://www.kaggle.com/alexisbcook/proximity-analysis)\n",
        "    # To do:\n",
        "    #   1) check this approach\n",
        "      \n",
        "    # Get both types of cities: cities with powiat rights (Q925381), urban municipality of Poland (Q2616791), and the the \"regular\" cities (Q515)\n",
        "    # https://docs.python.org/3/reference/lexical_analysis.html#f-strings\n",
        "    # https://query.wikidata.org/#SELECT%20%3Fcity%20%3FcityLabel%20%3Flatitude%20%3Flongitude%20%3FgeoPrecision%20%3Fcoord%0AWHERE%20%7B%0A%20%20%3Fcity%20%20wdt%3AP31%20wd%3AQ925381%3B%0A%20%20%20%20%20%20%20%20%20wdt%3AP17%20wd%3AQ36%3B%0A%20%20%20%20%20%20%20%20%20%23wdt%3AP131%20wd%3AQ54169%3B%0A%20%20%20%20%20%20%20%20%20p%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20psv%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLatitude%20%3Flatitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLongitude%20%3Flongitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoPrecision%20%20%3FgeoPrecision%3B%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D%3B%0A%20%20%20%20%20%20%20%20%20ps%3AP625%20%3Fcoord%20%0A%20%20%20%20%20%20%20%20%20%5D%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22pl%22.%20%7D%0A%7D\n",
        "    # https://query.wikidata.org/#SELECT%20%3Fcity%20%3FcityLabel%20%3Flatitude%20%3Flongitude%20%3FgeoPrecision%20%3Fcoord%0AWHERE%20%7B%0A%20%20%3Fcity%20%20wdt%3AP31%20wd%3AQ515%3B%0A%20%20%20%20%20%20%20%20%20wdt%3AP17%20wd%3AQ36%3B%0A%20%20%20%20%20%20%20%20%20%23wdt%3AP131%20wd%3AQ54169%3B%0A%20%20%20%20%20%20%20%20%20p%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20psv%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLatitude%20%3Flatitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLongitude%20%3Flongitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoPrecision%20%20%3FgeoPrecision%3B%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D%3B%0A%20%20%20%20%20%20%20%20%20ps%3AP625%20%3Fcoord%20%0A%20%20%20%20%20%20%20%20%20%5D%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22pl%22.%20%7D%0A%7D\n",
        "    cities_all = pd.DataFrame()\n",
        "    url = 'https://query.wikidata.org/sparql'\n",
        "    data = pd.DataFrame()\n",
        "    types_of_city = {'city with powiat rights': 'Q925381', 'urban municipality of Poland ': 'Q2616791', 'city': 'Q515'}\n",
        "    for type_of_city, type_of_city_sparql in types_of_city.items():\n",
        "#         print('\\n\\nCities of type \\'' + type_of_city + '\\' (' + str(type_of_city_sparql) + '):')\n",
        "        query = f''' \n",
        "            SELECT ?city ?cityLabel ?latitude ?longitude ?geoPrecision ?coord\n",
        "            WHERE {{\n",
        "              ?city  wdt:P31 wd:{type_of_city_sparql};\n",
        "                     wdt:P17 wd:Q36;\n",
        "                     #wdt:P131 wd:Q54169;\n",
        "                     p:P625 [\n",
        "                             psv:P625 [\n",
        "                                       wikibase:geoLatitude ?latitude ;\n",
        "                                       wikibase:geoLongitude ?longitude ;\n",
        "                                       wikibase:geoPrecision  ?geoPrecision;      \n",
        "                                      ];\n",
        "                     ps:P625 ?coord \n",
        "                     ]\n",
        "              SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"pl\". }}\n",
        "            }}\n",
        "            '''\n",
        "        r = requests.get(url, params = {'format': 'json', 'query': query})\n",
        "        data = r.json()\n",
        "\n",
        "        \n",
        "        # Convert json to dataframe\n",
        "        cities = []\n",
        "        for item in data['results']['bindings']:\n",
        "#             print(item,'\\n')    \n",
        "            cities.append(OrderedDict(\n",
        "            {\n",
        "                'city':             item['cityLabel']['value'].lower(),\n",
        "                'latitude':         float(item['latitude']['value']),        \n",
        "                'longitude':        float(item['longitude']['value']),                    \n",
        "                'geoPrecision':     float(item['geoPrecision']['value']),                                \n",
        "                'wikidata_item_id': item['city']['value'].split('/')[-1]\n",
        "            }))\n",
        "        cities = pd.DataFrame(cities).sort_values(by=['city']).reset_index(drop=True)\n",
        "#         print('Number of cities of type', type_of_city+':', len(cities))\n",
        "\n",
        "        \n",
        "        # Find those city names that have multiple instaces:\n",
        "        #   - those with the same wikidata_item_id are the same city with multiple coordinate sets - retain only the set with best (lowest) geoPrecision,\n",
        "        #   - those with different wikidata_item_id are different cities and should not be considered with the following procedure.\n",
        "        # https://stackoverflow.com/questions/55360314/pandas-groupby-take-counts-greater-than-1\n",
        "        cities_with_the_same_name_and_wikidataItemId = cities.loc[cities.groupby(['city', 'wikidata_item_id'])['geoPrecision'].transform('count') > 1].reset_index(drop=True) # cities.loc[cities.duplicated(subset=['city', 'wikidata_item_id'], keep=False)].reset_index(drop=True)\n",
        "#         print('Cities with the same name and the same wikidata_item_id:', len(cities_with_the_same_name_and_wikidataItemId))\n",
        "        \n",
        "    \n",
        "        # If multiple instances of any city exist, retain only the one with the best precision (lowest value) \n",
        "#         print('Cities with multiple instances:', len(cities_with_the_same_name_and_wikidataItemId), '\\n')\n",
        "        for city in cities_with_the_same_name_and_wikidataItemId['city'].unique():\n",
        "#             print(city)\n",
        "            city_to_retain_idx = cities_with_the_same_name_and_wikidataItemId.loc[cities_with_the_same_name_and_wikidataItemId['city'] == city, 'geoPrecision'].idxmin()        \n",
        "            cities_to_drop = cities_with_the_same_name_and_wikidataItemId.loc[(cities_with_the_same_name_and_wikidataItemId['city'] == city) & (cities_with_the_same_name_and_wikidataItemId.index != city_to_retain_idx)].index\n",
        "#             print('city:', city, '\\nindex and geoPrecision of instance to retain:', city_to_retain_idx, cities_with_the_same_name_and_wikidataItemId.loc[city_to_retain_idx, 'geoPrecision'], '\\nindices and geoPrecisions of instances to drop:\\n', tabulate(cities_with_the_same_name_and_wikidataItemId.loc[cities_to_drop, ['geoPrecision']], tablefmt='psql'))\n",
        "            cities = cities.drop(cities_to_drop).reset_index(drop=True)\n",
        "#         print('Number of cities with multiple instances of given cities after cleaning:', len(cities_with_the_same_name_and_wikidataItemId))\n",
        "\n",
        "\n",
        "        # Append to cities_all\n",
        "        cities_all = pd.concat([cities_all, cities], axis = 0).sort_values(by=['city']).reset_index(drop=True)\n",
        "#         print('Number of cities of type', type_of_city, 'after cleaning duplicate coordinates:', len(cities))\n",
        "\n",
        "    \n",
        "#     print('Number of all cities:', len(cities_all), '\\n', '#'*72)\n",
        "    return cities_all"
      ],
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iS1TurYI9hM"
      },
      "source": [
        "#code written by Maciej Kozubal",
        "def get_counties():\n",
        "    # Description:\n",
        "    #  - sparql query is constructed for counties ('Q247073'),\n",
        "      \n",
        "    # Get both types of cities: cities with powiat rights (Q925381), urban municipality of Poland (Q2616791), and the the \"regular\" cities (Q515)\n",
        "    # https://docs.python.org/3/reference/lexical_analysis.html#f-strings\n",
        "    # https://query.wikidata.org/#SELECT%20%3Fcity%20%3FcityLabel%20%3Flatitude%20%3Flongitude%20%3FgeoPrecision%20%3Fcoord%0AWHERE%20%7B%0A%20%20%3Fcity%20%20wdt%3AP31%20wd%3AQ247073%3B%0A%20%20%20%20%20%20%20%20%20wdt%3AP17%20wd%3AQ36%3B%0A%20%20%20%20%20%20%20%20%20wdt%3AP131%20wd%3AQ54169%3B%0A%20%20%20%20%20%20%20%20%20p%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20psv%3AP625%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLatitude%20%3Flatitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoLongitude%20%3Flongitude%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3AgeoPrecision%20%20%3FgeoPrecision%3B%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D%3B%0A%20%20%20%20%20%20%20%20%20ps%3AP625%20%3Fcoord%20%0A%20%20%20%20%20%20%20%20%20%5D%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22pl%22.%20%7D%0A%7D\n",
        "    cities_all = pd.DataFrame()\n",
        "    url = 'https://query.wikidata.org/sparql'\n",
        "    query = '''\n",
        "    SELECT ?county ?countyLabel ?latitude ?longitude ?geoPrecision ?coord\n",
        "    WHERE {\n",
        "      ?county  wdt:P31 wd:Q247073;\n",
        "            wdt:P17 wd:Q36;\n",
        "            wdt:P131 wd:Q54169;\n",
        "            p:P625 [\n",
        "                    psv:P625 [\n",
        "                              wikibase:geoLatitude ?latitude ;\n",
        "                              wikibase:geoLongitude ?longitude ;\n",
        "                              wikibase:geoPrecision  ?geoPrecision;      \n",
        "                              ];\n",
        "            ps:P625 ?coord \n",
        "            ]\n",
        "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"pl\". }\n",
        "    }\n",
        "    '''\n",
        "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
        "#     print(r.json())\n",
        "    data = r.json()\n",
        "\n",
        "    # convert json to dataframe\n",
        "    counties = []\n",
        "    for item in data['results']['bindings']:\n",
        "#         print(item,'\\n')    \n",
        "        counties.append(OrderedDict(\n",
        "        {\n",
        "            'county':           item['countyLabel']['value'].lower(),\n",
        "            'latitude':         float(item['latitude']['value']),        \n",
        "            'longitude':        float(item['longitude']['value']),                    \n",
        "            'geoPrecision':     float(item['geoPrecision']['value']),                                \n",
        "            'wikidata_item_id': item['county']['value'].split('/')[-1]\n",
        "        }))\n",
        "    \n",
        "    counties = pd.DataFrame(counties).sort_values(by=['county'])\n",
        "      \n",
        "    return counties"
      ],
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqZDj2pQ8JS6"
      },
      "source": [
        "#dfCities=get_cities()\n",
        "#dfCounties=get_counties()\n",
        "#dfVoivodeships=get_voivodeships()\n",
        "#dfWarsawDistricts=get_warsaw_districts()"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIAiPJZpdldk"
      },
      "source": [
        "#code written by Maciej Kozubal",
        "def return_coordinates(place,type):\n",
        "    '''\n",
        "    Returns coordinates of the place.\n",
        "        The place must be the name (in polish) of voivodeship in Poland, city, or the district of Warsaw.\n",
        "    '''\n",
        "    \n",
        "    coordinates = [None, None]\n",
        "    place = place.lower()\n",
        "    if type=='V':\n",
        "      print('voivodeships',place)\n",
        "\n",
        "      try:\n",
        "          voivodeships = get_voivodeships()\n",
        "          coordinates_df = voivodeships.loc[voivodeships['voivodeship'].str.contains(place) == True, ['latitude', 'longitude']]\n",
        "          coordinates = coordinates_df.values.tolist()[0]       \n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "    elif type=='D':\n",
        "      print('warsaw districts',place)\n",
        "      try:\n",
        "          counties = get_counties()\n",
        "          coordinates_df = counties.loc[counties['warsaw_district'].str.contains(place) == True, ['latitude', 'longitude']]\n",
        "          coordinates = coordinates_df.values.tolist()[0]\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "    elif type=='C':   \n",
        "      print('cities',place)\n",
        "      try:\n",
        "          cities = get_cities()\n",
        "          coordinates_df = cities.loc[cities['city'].str.contains(place) == True, ['latitude', 'longitude']]\n",
        "          coordinates = coordinates_df.values.tolist()[0]\n",
        "      except Exception as e:\n",
        "          print(e)   \n",
        "    print(coordinates)\n",
        "    return coordinates"
      ],
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyCylFst7j1X"
      },
      "source": [
        "def makeDataFrame(file):\n",
        "    dfMazowieckie=pd.read_csv(file,index_col=0)\n",
        "    concat=dfMazowieckie\n",
        "    concat['powierzchnia_corr'] = concat['powierzchnia'].apply(lambda x: toNum1(x))\n",
        "    concat['powierzchniaDzialki_corr'] = concat['powierzchniaDzialki'].apply(lambda x: toNum2(x))\n",
        "    concat['cena_corr'] = concat['cena'].apply(lambda x: toNum2(x))\n",
        "    concat['rokBudowy_corr'] = concat['rokBudowy'].apply(lambda x: toNum3(x))\n",
        "    concat['cena/m'] = concat['cena_corr'] / concat['powierzchnia_corr']\n",
        "    concat['lPieter_crr'] = concat['lPieter'].apply(lambda x: pietra(x))\n",
        "    concat = concat[concat['powierzchnia_corr'] > 0]\n",
        "    concat = concat[concat['cena_corr'] > 0]\n",
        "    concat['lPokoi'] = concat['lPokoi'].apply(lambda x: toNum3(x))\n",
        "    concat['districts']=concat['dzielnica'].apply(lambda x: x.split()[4])\n",
        "    cities_corr=concat['dzielnica'].apply(lambda x: cities(x))\n",
        "    concat['cities_corr']=cities_corr\n",
        "    region_corr=concat['dzielnica'].apply(lambda x: region(x))\n",
        "    concat['region_corr']=region_corr\n",
        "    concat_dropped = concat.drop(['dzielnica', 'powierzchnia', 'powierzchniaDzialki', 'lPieter', 'cena', 'cena_corr',], axis=1)\n",
        "    #['rokBudowy_corr'] = concat_dropped['rokBudowy_corr'].replace(to_replace=0, value=1990)\n",
        "    concat_dropped['rokBudowy_corr'] = concat_dropped['rokBudowy_corr'].astype('int')\n",
        "    concat_dropped.loc[concat_dropped['rokBudowy_corr']<1900,'rokBudowy_corr']=1980\n",
        "    concat_dropped.loc[concat_dropped['rokBudowy_corr']>2030,'rokBudowy_corr']=2020\n",
        "    #concat_dropped = concat_dropped[concat_dropped['rokBudowy_corr'] < 2030]\n",
        "    concat_dropped = concat_dropped.fillna(0)\n",
        "    concat_dropped = concat_dropped[concat_dropped['cena/m'] < 20000]\n",
        "    concat_dropped['cena/m'].hist(bins=200)\n",
        "\n",
        "    #concat_dropped_dumm = pd.get_dummies(concat_dropped, columns=['rodzajZabudowy', 'materialBudynku', 'stanWykonczenia', 'okna', 'rynek',\n",
        "    #                                       'cities_corr','districts','region_corr'])\n",
        "    \n",
        "    cityData=concat_dropped.cities_corr.apply(lambda x: funCities(x))\n",
        "    locationCities=locCities(cityData)\n",
        "    districtsData=concat_dropped.region_corr.apply(lambda x: funDistricts(x))\n",
        "    locationDistricts=locCities(districtsData)\n",
        "    countyData=concat_dropped.districts.apply(lambda x: funCounties(x))\n",
        "    locationCounty=locCounties(countyData)\n",
        "\n",
        "    concat_dropped_reset=concat_dropped.reset_index().drop(['index'],axis=1)\n",
        "    locations= pd.concat([locationCities,locationDistricts,locationCounty], axis=1)\n",
        "    concat_dropped_reset['locationX']=locations.apply(selectLocationX,axis=1)\n",
        "    concat_dropped_reset['locationY']=locations.apply(selectLocationY,axis=1)\n",
        "    concat_dropped_reset_drop = concat_dropped_reset.drop(['rokBudowy', 'districts', 'cities_corr', 'region_corr'], axis=1)\n",
        "    \n",
        "\n",
        "    return concat_dropped_reset_drop"
      ],
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAA1mSAY9P8O"
      },
      "source": [
        "def funCities(x):\n",
        "  rows=dfCities.loc[dfCities['city']==x.lower()]\n",
        "  precision=0\n",
        "  if rows.shape[0]==0:\n",
        "    return 0,0,100\n",
        "  elif rows.shape[0]==1:\n",
        "    longitude=rows.longitude.values\n",
        "    latitude=rows.latitude.values\n",
        "    precision=rows.geoPrecision.values\n",
        "    return longitude[0],latitude[0],precision[0]\n",
        "  elif rows.shape[0]>1:\n",
        "    prec1,prec2=rows.iloc[0,3],rows.iloc[1,3]\n",
        "    if prec1<prec2:\n",
        "      precision=prec1\n",
        "      longitude=rows.iloc[0,2]\n",
        "      latitude=rows.iloc[0,1]\n",
        "    else:\n",
        "      precision=prec2\n",
        "      longitude=rows.iloc[1,2]\n",
        "      latitude=rows.iloc[1,1]\n",
        "    return longitude,latitude,precision"
      ],
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quM6ZeSO9UdN"
      },
      "source": [
        "def funDistricts(x):\n",
        "  rows=dfWarsawDistricts.loc[dfWarsawDistricts['warsaw_district']==x.lower()]\n",
        "  #print(x, ' ',rows.shape[0])\n",
        "  if rows.shape[0]==0:\n",
        "    return 0,0,100\n",
        "  elif rows.shape[0]==1:\n",
        "    longitude=rows.longitude.values\n",
        "    latitude=rows.latitude.values\n",
        "    precision=rows.geoPrecision.values\n",
        "    return longitude[0],latitude[0],precision[0]"
      ],
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "domiHiOr9R4d"
      },
      "source": [
        "def funCounties(x):\n",
        "  try:\n",
        "    rows=dfCounties.loc['powiat '+x.lower()== dfCounties['county']]\n",
        "  except Exception as e:\n",
        "    return e\n",
        "  #print(x, ' ',rows.shape[0])\n",
        "  if rows.shape[0]==0:\n",
        "    return 0,0,100\n",
        "  elif rows.shape[0]==1:\n",
        "    longitude=rows.longitude.values\n",
        "    latitude=rows.latitude.values\n",
        "    precision=rows.geoPrecision.values\n",
        "    return longitude[0],latitude[0],precision[0]"
      ],
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW1CIMKJfS3d"
      },
      "source": [
        "def selectLocationX(x):\n",
        " # print(x[17],x[20],x[23])\n",
        "  if x[2]<min(x[5],x[8]):\n",
        "    #print('min 17',x[15],x[16])\n",
        "    return x[0]\n",
        "  elif x[5]<min(x[2],x[8]):\n",
        "    #print('min 20 ',x[18],x[19])\n",
        "    return x[3]\n",
        "  elif x[8]<min(x[2],x[5]):\n",
        "    #print('min 23 ',x[21],x[22])\n",
        "    return x[6]\n",
        "\n",
        "def selectLocationY(x):\n",
        " # print(x[17],x[20],x[23])\n",
        "  if x[2]<min(x[5],x[8]):\n",
        "    #print('min 17',x[15],x[16])\n",
        "    return x[1]\n",
        "  elif x[5]<min(x[2],x[8]):\n",
        "    #print('min 20 ',x[18],x[19])\n",
        "    return x[4]\n",
        "  elif x[8]<min(x[2],x[5]):\n",
        "    #print('min 23 ',x[21],x[22])\n",
        "    return x[7]"
      ],
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4XnJiBnZlgN"
      },
      "source": [
        "def locCities(cityData):\n",
        "  locationCities=[]\n",
        "  for data in cityData:\n",
        "    locationCities.append(data)\n",
        "  locationCities=pd.DataFrame(np.array(locationCities),columns=['cityX','cityY','cityGeo'])\n",
        "  return locationCities\n",
        "\n",
        "def locDistricts(districtsData):\n",
        "  locationCities=[]\n",
        "  for data in cityData:\n",
        "    locationDistricts.append(data)\n",
        "  locationDistricts=pd.DataFrame(np.array(locationDistricts),columns=['cityX','cityY','cityGeo'])\n",
        "  return locationDistricts\n",
        "\n",
        "def locCounties(countyData):\n",
        "  locationCounty=[]\n",
        "  for data in countyData:\n",
        "    locationCounty.append(data)\n",
        "  locationCounty=pd.DataFrame(np.array(locationCounty),columns=['countyX','countyY','countyGeo'])\n",
        "  return locationCounty"
      ],
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmOjGx4Z7lbR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "71f6268c-ef60-477b-d574-f9459708b97a"
      },
      "source": [
        "filename='/content/drive/My Drive/domymazowieckie/dfMazowieckie.csv'\n",
        "dfCities=get_cities()\n",
        "dfCounties=get_counties()\n",
        "dfVoivodeships=get_voivodeships()\n",
        "dfWarsawDistricts=get_warsaw_districts()"
      ],
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ChunkedEncodingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 16: b''",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                 \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mhttplib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(0 bytes read)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# This includes IncompleteRead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Connection broken: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(0 bytes read)', IncompleteRead(0 bytes read))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-396-fdeb204b5738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/My Drive/domymazowieckie/dfMazowieckie.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfCities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_cities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdfCounties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_counties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdfVoivodeships\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_voivodeships\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdfWarsawDistricts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_warsaw_districts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-384-40c33d3e2741>\u001b[0m in \u001b[0;36mget_cities\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m             }}\n\u001b[1;32m     39\u001b[0m             '''\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'format'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'query'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mContentDecodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mChunkedEncodingError\u001b[0m: ('Connection broken: IncompleteRead(0 bytes read)', IncompleteRead(0 bytes read))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl-GYCGD7mwf"
      },
      "source": [
        "final=makeDataFrame(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZWpjluqKkdW"
      },
      "source": [
        "filename_json='/content/drive/My Drive/domymazowieckie/dfMazowieckie.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz8dYhWJKaYw"
      },
      "source": [
        "final.to_json(filename_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-tN-Z-L0dJ6"
      },
      "source": [
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffZlHNQaDKfW"
      },
      "source": [
        "plt.hist(final.loc[:,'lPokoi']/10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS1BFK5NFkCJ"
      },
      "source": [
        "sns.boxplot(x=(np.log(final[\"powierzchnia_corr\"])/10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6Qi89r8GWTJ"
      },
      "source": [
        "sns.boxplot(x=(np.log(final[\"powierzchniaDzialki_corr\"]+1)/14))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIFvJRm_GlIl"
      },
      "source": [
        "sns.boxplot(x=(np.power(final[\"rokBudowy_corr\"]-1899,4)/3e8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxoUv1XPKlDA"
      },
      "source": [
        "plt.hist(np.power(final[\"rokBudowy_corr\"]-1899,4)/3e8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NyrjT8CMiny"
      },
      "source": [
        "sns.boxplot(x=final[\"cena/m\"]/20000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHQa0jmgM3tO"
      },
      "source": [
        "sns.boxplot(x=final[\"lPieter_crr\"]/10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpjahNPgNFWG"
      },
      "source": [
        "plt.hist(final[\"lPieter_crr\"]/10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB9L8WI_NL43"
      },
      "source": [
        "plt.hist((final[\"locationX\"]-21)/4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGiQ-Rv7PUsY"
      },
      "source": [
        "plt.hist((final[\"locationY\"]-52)/2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeO3l4r6DDRX"
      },
      "source": [
        "final.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFYF-KTDoqTH"
      },
      "source": [
        "final=final[final['powierzchnia_corr']<500]\n",
        "final=final[final['powierzchniaDzialki_corr']<5000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REg4TI2B0Hjm"
      },
      "source": [
        "final['powierzchnia_corr'].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el2Z_7Yl07lL"
      },
      "source": [
        "final_plots=final.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed_mrehAzkmO"
      },
      "source": [
        "dummies = pd.get_dummies(final_plots, columns=['rodzajZabudowy', 'materialBudynku', 'stanWykonczenia', 'okna', 'rynek'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FjkSlegQD4r"
      },
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv5v9K_5Qy10"
      },
      "source": [
        "final_plots.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQKdCjCDoU0w"
      },
      "source": [
        "df=pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIac6Sp3moBu"
      },
      "source": [
        "final_plots1=final_plots[['powierzchnia_corr','cena/m']].copy()#'lPokoi','lPieter_crr',,'powierzchniaDzialki_corr','rokBudowy_corr',,'locationX','locationY'\n",
        "#df['lPokoi']=final_plots.loc[:,'lPokoi']/10\n",
        "df[\"powierzchnia_corr\"]=np.log(final_plots1[\"powierzchnia_corr\"])/3-1\n",
        "#df[\"powierzchniaDzialki_corr\"]=np.log(final_plots[\"powierzchniaDzialki_corr\"]+1)/14\n",
        "#df[\"rokBudowy_corr\"]=np.power(final_plots[\"rokBudowy_corr\"]-1899,4)/3e8\n",
        "df[\"cena/m\"]=final_plots1[\"cena/m\"]/20000\n",
        "#df[\"locationX\"]=(final_plots[\"locationX\"]-21)/4\n",
        "#df[\"locationY\"]=(final_plots[\"locationY\"]-52)/4\n",
        "#df['lPieter_crr']=final_plots.loc[:,'lPieter_crr']/10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnkXQHKioP1h"
      },
      "source": [
        "df[\"powierzchnia_corr\"].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-FBrxi210iv"
      },
      "source": [
        "df[\"cena/m\"].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-rdIHedtljp"
      },
      "source": [
        "print(df.shape)\n",
        "print(dummies.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POC4RKeosjKH"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-4JB51ipKk9"
      },
      "source": [
        "#final_plots=final[['powierzchnia_corr','powierzchniaDzialki_corr','rokBudowy_corr','cena/m','locationX','locationY']].copy()\n",
        "#final_plots=final_plots[final_plots['powierzchnia_corr']<1500]\n",
        "#final_plots=final_plots[final_plots['powierzchniaDzialki_corr']<5000]\n",
        "#final_no_dummies=final_no_dummies[final_no_dummies['powierzchnia_corr']<1500]\n",
        "#final_no_dummies=final_no_dummies[final_no_dummies['powierzchniaDzialki_corr']<5000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TNJO-MXQhd8"
      },
      "source": [
        "df.locationX=df.locationX.fillna(10)\n",
        "df.locationY=df.locationY.fillna(40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgf7ugsATA3V"
      },
      "source": [
        "values=[]\n",
        "for i in [2,3,4,5,6,7,8,9,10,11,12,13,14]:\n",
        "  kmeans = KMeans(n_clusters=i, random_state=0).fit(df.values)\n",
        "  values.append(kmeans.score(df.values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn-9iCmLnvvo"
      },
      "source": [
        "print(np.abs(values))\n",
        "print(values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSwmHR1Qqii_"
      },
      "source": [
        "plt.plot(np.abs(values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFTGRTRosh84"
      },
      "source": [
        "kmeans = KMeans(n_clusters=5, random_state=0).fit(df.values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmz9K2HfTao3"
      },
      "source": [
        "final_plots['kmean']=kmeans.predict(df.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me8zC4_GUyRd"
      },
      "source": [
        "final_plots.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qxJ4b5xmAyw"
      },
      "source": [
        "final_plots['powierzchnia_cat']=(final_plots['powierzchnia_corr']/50).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTQs01IbwnpA"
      },
      "source": [
        "final_plots['powierzchnia_corr'].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4poz8zZDpMnX"
      },
      "source": [
        "sns.catplot(y=\"materialBudynku\", x=\"cena/m\", hue=\"kmean\", kind=\"boxen\", data=final_plots,height=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kOu12Y8VF4M"
      },
      "source": [
        "sns.catplot(y=\"rodzajZabudowy\", x=\"cena/m\", hue=\"kmean\", kind=\"boxen\", data=final_plots,height=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzLeHn1jlsqQ"
      },
      "source": [
        "sns.catplot(x=\"powierzchnia_cat\", y=\"cena/m\", hue=\"kmean\", kind=\"boxen\", data=final_plots,height=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5BEUbAyeUJv"
      },
      "source": [
        "sns.relplot(y=\"locationY\", x=\"locationX\", hue=\"kmean\", data=final_plots,size='cena/m',height=10, sizes=(1, 1000),palette=\"muted\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rucmuamysMZc"
      },
      "source": [
        "sns.relplot(y=\"locationY\", x=\"locationX\", hue=\"kmean\", data=final_plots[(final_plots[\"locationX\"]>20) & (final_plots[\"locationX\"]<21.5)&\n",
        "                                                                             (final_plots[\"locationY\"]>52) & (final_plots[\"locationY\"]<52.5)],size='cena/m',height=10, sizes=(1, 1000),palette=\"muted\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
